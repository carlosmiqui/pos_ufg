# Importação das bibliotecas necessárias
from openai import OpenAI
from dotenv import load_dotenv
import os
from guardrails.hub import RestrictToTopic
from guardrails import Guard

# Carregar variáveis de ambiente do arquivo .env
load_dotenv()

# Configurar a chave da API da OpenAI (chave dentro do arquivo .env)
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("A chave da API 'OPENAI_API_KEY' não foi encontrada. Verifique o arquivo .env.")

# Inicializar o cliente da OpenAI
client = OpenAI(api_key=api_key)

# Inicializar o Guard com RestrictToTopic para validar tópicos relacionados ao contexto desejado
guard = Guard().use(
    RestrictToTopic(
        valid_topics=[
            "relationship building", "client engagement", "professional interaction",
            "appointment scheduling", "service differentiation", "client needs assessment",
            "customer feedback", "client satisfaction", "personalized care",
            "healthcare expertise", "innovative treatments", "clinic amenities",
            "follow-up care", "patient testimonials", "communication skills",
            "trust building", "service excellence", "consultation benefits",
            "patient experience", "clinic reputation", "health education",
            "value proposition", "customer loyalty", "problem solving",
            "client retention", "wellness programs", "health advice",
            "customer service", "patient journey", "healthcare trends"
        ],
        invalid_topics=[],  # Assumimos que todos os tópicos não listados são inválidos por padrão
        disable_classifier=True,
        disable_llm=False,
        on_fail="exception"
    )
)

# Histórico da conversa
conversation_history = [
    {"role": "system", "content": "Você é um assistente útil e bem informado, sempre respondendo com detalhes e clareza."}
]

def validate_input(user_input):
    """
    Valida o input do usuário para garantir que está dentro dos tópicos permitidos.
    """
    try:
        # Validar o input do usuário
        result = guard.validate(user_input)
        return result.validation_passed
    except Exception:
        # Retornar False se a validação falhar
        return False

def interact_with_gpt(user_input):
    """
    Função que interage com o GPT-4o-mini, enviando o histórico de conversas atualizado e recebendo a resposta.
    """
    # Adicionar a entrada do usuário ao histórico
    conversation_history.append({"role": "user", "content": user_input})
    
    try:
        # Solicitar uma conclusão do modelo
        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=conversation_history
        )
        
        # Extrair a resposta do modelo
        response = completion.choices[0].message.content
        
        # Adicionar a resposta ao histórico
        conversation_history.append({"role": "assistant", "content": response})
        
        return response
    except Exception as e:
        return f"Ocorreu um erro ao interagir com o modelo: {e}"

# Loop principal para interação do usuário
print("Bem-vindo! Digite suas perguntas ou 'sair' para encerrar.")
while True:
    user_input = input("Você: ")
    if user_input.lower() == "sair":
        print("Encerrando a conversa. Até logo!")
        break
    
    # Validar o input do usuário
    if validate_input(user_input):
        # Obter resposta do GPT-4o-mini
        response = interact_with_gpt(user_input)
        print(f"GPT: {response}")
    else:
        print("O tópico da sua pergunta não é válido. Por favor, reformule sua pergunta para estar dentro dos tópicos permitidos (criação de relacionamento entre cliente e profissional).")
